#!/usr/bin/env ruby

puts "==> Loading Rails environment ..."
require File.expand_path '../../config/environment', __FILE__

raise "This script is not safe to run in #{Rails.env}" unless Rails.env.development?

path = ARGV.first
raise "Please specify a file to load" unless path
puts "==> Reading data from '#{path}'"

data = {}
JSON.parse(File.read(path)).each do |obj|
  data[obj["model"]] ||= {}
  data[obj["model"]][obj["pk"]] = obj["fields"]
end

# -- Helpers -----
require 'import_buffer'

def import objs, klass, &block
  klass.delete_all
  ids = []
  ImportBuffer.new do |buffer|
    objs.each do |id, obj|
      attrs = block.call id, obj
      next unless attrs
      ids    << id
      buffer << klass.new(attrs)
    end
  end

  oids = klass.order('id ASC').pluck :id
  if ids.length == oids.length
    puts "  #{ids.length} #{klass.name.pluralize}"
  else
    binding.pry
  end
  klass.const_set 'Map', Hash[ids.zip oids]
end

# -- Snippets ------
puts "==> Finding descriptions"
content_types = data["contenttypes.contenttype"].inject({}) do |h, (_,v)|
  begin
    model = v["model"]
    h[model] = model.capitalize.constantize
  rescue
  end
  h
end
documents = Hash[ data["brubeck.document"] ] 
snippets  = Hash[ data["brubeck.snippet"]  ]

skipped = []
Descriptions = {}
data["brubeck.revision"].each.group_by do |id, r| 
  r["page"] 
end.each do |page_id, revisions|
  id, r   = revisions.max_by { |id, r| Time.parse r["timestamp"] }
  text    = r["text"]
  snippet = snippets[page_id]
  model   = content_types[snippet["content_type"][1]]
  next if text =~ /careerjobs/  # Residual spam cleanup
  next unless model
  if model == Trait && snippet["proof_agent"].present?
    text = "AUTOMATICALLY GENERATED"
  end
  begin
    Descriptions[[model, snippet["object_id"]]] = text
  rescue
    skipped << "  #{model}: #{text}" unless text.empty?
  end
end

unless skipped.empty?
  puts "Failed to update some descriptions:"
  skipped.each { |str| puts str }
end

# -- Imports -----
puts "==> Importing objects"
import data["brubeck.valueset"], ValueSet do |id, vs|
  {
    name: vs["name"]
  }
end

import data["brubeck.value"], Value do |id, v|
  {
    name: v["name"],
    value_set_id: ValueSet::Map[v["value_set"]]
  }
end

import data["brubeck.space"], Space do |id, s|
  { 
    name: s["name"],
    description: Descriptions[[Space, id]]
  }
end

import data["brubeck.property"], Property do |id, p|
  {
    name: p["name"],
    value_set_id: ValueSet::Map[p["value_set"]],
    description: Descriptions[[Property, id]]
  }
end

# Theorems are a bit of a special case since we have to serialize
def import_formula str
  if str[0] == '('
    conj = str[1]
    str[2..-2].split(',').map { |s| import_formula s }.inject &conj.to_sym
  else
    Formula::Atom.parse str
  end
end

Theorem.delete_all
data["brubeck.implication"].each do |id, t|
  ant = t["antecedent"].gsub /(\d+)=(\d+)/ do
    "#{Property::Map[$1.to_i]}=#{Value::Map[$2.to_i]}"
  end
  con = t["consequent"].gsub /(\d+)=(\d+)/ do
    "#{Property::Map[$1.to_i]}=#{Value::Map[$2.to_i]}"
  end
  t = Theorem.new({
    antecedent: import_formula(ant).to_s, 
    consequent: import_formula(con).to_s,
    description: Descriptions[[Theorem, id]]
  })
  t.save validate: false
end
puts "  #{Theorem.all.count} Theorems"

import data["brubeck.trait"], Trait do |id, t|
  description = Descriptions[[Trait, id]]
  next if description == "AUTOMATICALLY GENERATED"
  {
    space_id: Space::Map[t["space"]],
    property_id: Property::Map[t["property"]],
    value_id: Value::Map[t["value"]],
    description: description
  }
end

#-- Make an admin user -----
u = User.where(email: 'jamesdabbs@gmail.com').first_or_initialize
u.password = u.password_confirmation = 'password'
u.admin = true
u.save!

# puts "==> Writing descriptions to file"
# [Space, Property, Trait].each do |klass|
#   ext = klass == Trait ? :bmd : :md
#   klass.find_each do |obj|
#     File.open "#{Brubeck::GollumPath}/#{klass.name}/#{obj.name}.#{ext}", "w" do |f|
#       f.puts obj[:description]
#     end
#   end
# end

